# ğŸ§  AI Fairness Data Generation and Question Answering System

[![code checks](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/code_checks.yml/badge.svg)](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/code_checks.yml)
[![unit tests](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/unit_tests.yml/badge.svg)](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/unit_tests.yml)
[![integration tests](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/integration_tests.yml/badge.svg)](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/integration_tests.yml)
[![docs](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/docs.yml/badge.svg)](https://github.com/VectorInstitute/vector-aixpert/actions/workflows/docs.yml)

<!--
[![codecov](https://codecov.io/github/VectorInstitute/vector-aixpert/graph/badge.svg?token=83MYFZ3UPA)](https://codecov.io/github/VectorInstitute/vector-aixpert)
![GitHub License](https://img.shields.io/github/license/VectorInstitute/vector-aixpert)
-->

---

*Transparent tools and standardized benchmarks for **fair**, **explainable**, and **accountable** generative AI.*

> The rapid expansion of GenAI magnifies long-standing concerns around **bias, fairness, and representation**.
> This project enables systematic, controlled experimentation so researchers can identify *when* and *why* bias occurs, and test what mitigates it.

---

## ğŸŒ What is the project about?

The **AI Fairness Data Generation and Question Answering System** is part of **[Vector Institute's](https://vectorinstitute.ai)** contribution to the broader [AIXPERT Project](https://aixpert-project.eu/), a multi-institutional initiative, to develop tools and benchmarks for **fairness-aware data generation and evaluation** in generative AI.

It provides:

* ğŸ§© **Controlled synthetic datasets** â€” safely isolate bias-inducing factors.
* ğŸ¤– **Agentic automation** using **CrewAI** and custom LLM agents.
* ğŸ“Š **Fairness metrics & explainers** to visualize disparities.
* âš™ï¸ **Configurable, reproducible pipelines** for responsible AI research.

ğŸ“˜ **Documentation:** [Project website](https://vectorinstitute.github.io/vector-aixpert/)

ğŸ“‚ **Data:** [Hugging Face](https://huggingface.co/datasets/vector-institute/aixpert)

ğŸ§® **Code:** [GitHub Page](https://github.com/VectorInstitute/vector-aixpert)

---

## ğŸ§± Repository Structure

| Path                                                            | Description                                                           |
| --------------------------------------------------------------- | --------------------------------------------------------------------- |
| `src/aixpert/controlled_images/`                                | Controlled image generation (baseline vs fairness-aware).             |
| `src/aixpert/data_generation/synthetic_data_generation/images/` | Domain- and risk-specific image + VQA generation.                     |
| `src/aixpert/data_generation/synthetic_data_generation/nlp/`    | Domain- and risk-specific Scene + MCQ generation.                                      |
| `src/aixpert/data_generation/synthetic_data_generation/videos/` | Video synthesis using Google Veo / Gemini API.                        |
| `src/aixpert/data_generation/agent_pipeline/`                   | Single-agent **CrewAI** pipeline for multimodal orchestration.        |
| `src/aixpert/toxicity_fairness_analysis/`                                    | Fairness metrics and zero-shot explainability (integrated gradients). |
| `docs/`                                                         | MkDocs documentation sources.                                         |
| `tests/`                                                        | Tests using `pytest`.                            |

---

## ğŸš€ Getting Started

New to the project? Follow the steps below to set up your development environment and explore key modules.

### Prerequisites

Ensure you have [uv](https://docs.astral.sh/uv/getting-started/installation/) installed (recommended environment manager).

### Quick setup
```bash
# 1) Create the environment
uv sync
source .venv/bin/activate

# 2) (Optional) Install dev tools
uv sync --dev

# 3) (Optional) Install and Serve docs
uv sync --no-group docs
uv run mkdocs serve
````

### Module quick start (one-liners + deep links)

Each module below has its own README with exact commands, configs, and outputs.

* **Controlled Images** â€” Generate matched baseline vs fairness-aware images across professions.
  âœ [`src/aixpert/controlled_images/README.md`](src/aixpert/controlled_images/README.md)

* **Agent Pipeline (CrewAI)** â€” Single-agent orchestration for prompt/image/metadata generation.
  âœ [`src/aixpert/data_generation/agent_pipeline/README.md`](src/aixpert/data_generation/agent_pipeline/README.md)

* **Synthetic Data Â· Images** â€” Domain/risk-specific image prompts and VQA pairs.
  âœ [`src/aixpert/data_generation/synthetic_data_generation/images/README.md`](src/aixpert/data_generation/synthetic_data_generation/images/README.md)

* **Synthetic Data Â· NLP** â€” Scene descriptions and MCQ generation for text pipelines.
  âœ [`src/aixpert/data_generation/synthetic_data_generation/nlp/README.md`](src/aixpert/data_generation/synthetic_data_generation/nlp/README.md)

<!--
# TODO: Add the video module readme when ready
# * **Synthetic Data Â· Videos** â€” Video synthesis via Google Veo / Gemini with checkpoint & resume.
  # âœ [`src/aixpert/data_generation/synthetic_data_generation/videos/README.md`](src/aixpert/data_generation/synthetic_data_generation/videos/README.md)
-->

* **Fairness & Explainability (Toxicity fairness analysis)** â€” Metrics (Statistical Parity, Equal Opportunity) + zero-shot explainers (integrated gradients).
  âœ [`src/aixpert/toxicity_fairness_analysis/README.md`](src/aixpert/toxicity_fairness_analysis/README.md)

* **Documentation** â€” MkDocs site sources; how to extend and publish docs.
  âœ [`CONTRIBUTING.md`](CONTRIBUTING.md)

<!--
* **Tests** â€” Run unit/integration tests with `pytest` and pre-commit hooks.
  âœ [`tests/README.md`](tests/README.md)
-->

<!-- # TODO: Add the website link when the docs are published on GitHub Pages
# > Prefer a website? See the full docs:
# > ğŸ”— **AIXpert website** â€” [https://vectorinstitute.github.io/AIXpert/](https://vectorinstitute.github.io/vector-aixpert/)
 -->

---

## ğŸ§  Key Components

* **ğŸ¨ Controlled Image Generation:** Produces matched baseline vs fairness-aware images across professions.
* **ğŸ¤– Agentic AI (CrewAI):** LLM-based prompt, image, and metadata orchestration.
* **ğŸ§¾ Synthetic Data Generation:** Domain/risk-specific image prompts, VQA pairs, scenes, and MCQs.
* **ğŸ¬ Video Generation:** Uses Google Veo/Gemini APIs with checkpoint and resume logic.
* **âš–ï¸ Fairness Metrics & Explainability:** Statistical Parity, Equal Opportunity, and zero-shot explainers with integrated gradients.

---

## ğŸ§ª Testing & CI/CD

* Unit and integration tests via `pytest`.
* Code quality enforced via `pre-commit` hooks:

  * `ruff` â€” linting & formatting
  * `mypy` â€” type checks
  * `typos` â€” spell checks
  * `nbQA` â€” notebook linting
* Continuous checks through GitHub Actions (see badges above).

---

## ğŸ“š Publications & Outputs

* ğŸ§© [*Bias in the Picture: Benchmarking VLMs with Social-Cue News Images*](https://arxiv.org/abs/2509.19659), NeurIPS LLM Evals Workshop 2025
* ğŸ“œ [*TRiSM for Agentic AI*](https://arxiv.org/abs/2506.04133), Preprint
* ğŸ“˜ [*Responsible Agentic Reasoning and AI Agents*](https://www.techrxiv.org/articles/1329333), TechRxiv
* ğŸ§  *Single-Agent TRiSM Poster (NeurIPS LAW Workshop 2025)*

---

## ğŸ¤ Contributing

We welcome community contributions!
See [CONTRIBUTING.md](CONTRIBUTING.md) for coding standards, dev setup, and workflow conventions.


---

## ğŸ“„ License

This code in this repo is released under the **MIT License**.

---

## ğŸ’¡ About AIXPERT

The **AIXPERT Project** unites 17 partners across Europe and Canada under the
**EU Horizon Europe Programme (Grant No. 101214389)** and the **Swiss SERI** to advance
**explainable, fair, and accountable AI**.

ğŸŒ [Project Website](https://aixpert-project.eu/) Â· [LinkedIn](https://www.linkedin.com/company/aixpert-project/) Â· [X/Twitter](https://x.com/AIXPERT_project) Â· [YouTube](https://www.youtube.com/@AIXPERT_project)

---

## ğŸ’° Funding Acknowledgment

> The **AIXPERT Project** has received funding from the **European Unionâ€™s Horizon Europe Research and Innovation Programme** under Grant No. **101214389**, and from the **Swiss State Secretariat for Education, Research and Innovation (SERI)**.
> Views expressed are those of the authors and do not necessarily reflect those of the European Union or funding authorities.
